# Elasticsearch

### Elasticsearch是什么？

- 实时的分布式搜索分析引擎
  - 数据在1秒后可以被检索到，准实时搜索
- 内部使用Lucene做索引与搜索
  - Java语言编写的全文搜索框架

- 适合中等数据量的业务

### 索引结构

- 索引

  - 分片

    > 一个分片是一个Lucene索引

    - 分段

      > 每个分段都是一个倒排索引
      >
      > 每次refresh都会生成一个新的分段

      - 文档

        - 字段

          - Term(词)

            > 原文本经过分词器处理和语言处理之后的结果

### 文档

- 删除

  - 以_id为单位删除文档不会立刻释放空间

  - 删除的doc只有在分段合并时才会真正从磁盘中删除
  - 建议周期性的创建索引

- 更新

  - 倒排索引一旦被写入文件后就具有不变性
    - 访问不需要加锁
    - 读取索引时可以被文件系统缓存
  - 每次内存缓冲的数据被写入文件时，会产生一个新的Lucene段
  - 更新、删除等操作实际上是标记删除

### 集群节点角色

- 主节点
  - 全局唯一
  - 管理集群变更

- 数据节点
  - 保存数据、执行数据相关操作
- 预处理节点
  - 通过事先定义好的一系列processors(处理器)和pipeline(管道)，对数据进行某种转换、富化
- 协调节点
  - 转发请求
  - 合并结果

- 部落节点
  - 路由请求，智能负载均衡器

### 集群状态

- Green，所有主分片和副分片都正常运行
- Yellow，所有主分片都正常运行，但不是所有副本分片都正常运作
- Red，有主分片没能正常运行

### 内部模块

- Cluster
  - 管理集群状态
  - 调用allocation模块执行分片分配
  - 迁移分片
- allocation
  - 分片分配
- Discovery
  - 发现节点
  - 选主节点
- gateway
  - 负责对收到Master广播下来的集群状态(cluster state)数据的持久化存储
- Indices
  - 全局级的索引设置
  - 索引数据恢复
- HTTP
  - 完全异步
- Transport
  - 内部通信
  - 使用TCP通信
- Engine
  - 封装了对Lucene的操作及translog的调用

### 集群启动

- 选主

- 选举集群元信息

- Allocation过程

  - 选主分片

    > 所有的分配工作都是Master来做的

  - 选副分片

- index recovery

  - 主分片recovery

    > 将最后一次提交之后的translog进行重放

    - 阶段一：

      - 获取translog保留锁

      - 做shard快照
      - 快照复制到副本分片

    - 阶段二：

      - 对translog做快照，包含从阶段一开始到执行translog快照期间的新增索引
      - 在副本分片重放

  - 副分片recovery

### 分布式一致性思路

- 避免不一致
  - 主从模式(Leader/Follower)
    - 集群中没有那么多节点
    - 节点数量远远小于单个节点能够维护的连接数
    - 网络环境不必经常处理节点的加入和离开
  - 分布式哈希表(DHT)，Cassandra就使用这种方案
- 发生不一致之后如何协调

### 选举算法

- Bully

  - 假定所有节点都有一个唯一ID

  - 任何时候当前的Leader都是参与集群的最高ID节点

  > 当拥有最大ID节点处于不稳定状态时，主节点会不断的切换
  >
  > ES通过延迟选举，只要当前主节点不挂，就不重新选举
  >
  > 但是容易产生脑裂，通过限定“法定得票人数过半”解决脑裂问题

- Paxos

  > 实现复杂

### 最小主节点数应用场景

> discovery.zen.minimum_master_nodes >= (master_eligible_nodes / 2) + 1

- 触发选主：参选节点数超过最小主节点数，才会触发选主
- 决定Master：选出临时Master后，加入它的节点数超过最小主节点数，才能确认选主成功
- gateway选举元信息：向有Master资格的节点发起请求，获取元数据，获取的响应数量必须达到最小主节点数
- Master发布集群状态：发布成功数量必须超过最小主节点数

### 选举流程

- 选举临时Master

  - 获取所有节点列表fullPingResponses

    - ping所有节点
    - 获取fullPingResponses列表
    - 将本机节点添加到列表中

  - 构建两个列表

    - activeMasters列表

      - 遍历fullPingResponses列表
      - 将每个节点所认为的当前Master节点加入到activeMasters列表
      - discovery.zen.master_election.ignore_non_master_pings为true且不具备Master资格，跳过

    - masterCandidates列表

      > master候选者列表

      - 遍历fullPingResponses列表
      - 跳过不具备Master资格的节点

  - 判断activeMasters列表是否为空

    - 如果为空，从masterCandidates中选举
      - 判断当前候选者人数是否达到最小主节点数
      - 将节点排序后，选择最小的节点作为Master
    - 如果不空，从activeMasters中选择最合适的作为Master
      - 取列表中ID最小的节点

- 判断选举出的临时Master是否是本节点

  - 是本节点
    - 等待足够多具备Master资格的节点加入本节点
    - 超时(默认30s)后仍没有满足数量，选举失败，重新选举
    - 成功后发布新的clusterState
  - 不是本节点
    - 不再接受其他节点join请求
    - 向master发送join请求，并等待回复，超时默认1min，失败重试3次
    - 当选的Master会发布集群状态，确认join请求。收到确认回复后，检查集群状态中的Master节点，如果为空，或者当选的Master不是之前选择的节点，重新选举

- 启动节点失效检测器

  > 定时(默认1s)发送ping请求，失败达到一定次数(默认3次)，或者收到底层连接模块的节点离线通知时，开始处理节点离开事件

  - 在Master节点启动NodesFaultDetection，简称NodesFD。定期探测加入集群的节点是否活跃

    > 主节点在探测到节点离线的事件处理中，如果发现当前集群节点数量不足最小主节点数，放弃Master身份

  - 在非Master节点启动MasterFaultDetection，简称MasterFD。定期探测Master节点是否活跃

    > 重新加入主节点，本质上就是该节点重新执行一次选主流程

### PacificA算法

- 核心概念

  - Replica Group

    > 一个互为副本的数据集合
    >
    > 只有一个是主数据(Primary)，其他是从数据(Secondary)

  - Configuration

    > 配置信息

    - 副本组中都有哪些副本
    - Primary是谁
    - 副本位于哪个节点

  - Configuration Version

    > 配置信息版本号，每次发生变更时递增

  - Serial Number，简称SN

    > 每个写操作的顺序，每次写操作时递增

  - Prepared List

    > 写操作准备序列，存储来自外部请求的列表，按照SN排序
    >
    > 每个副本有自己的Prepared List

  - Committed List

    > 写操作提交序列

- 数据副本策略
  - 使用主从模式
  - 多个副本中存在一个主副本(Primary)和多个从副本(Secondary)
  - 所有数据的写操作都进入主副本
  - 主副本故障时，系统从其他副本中选择合适的副本作为新的主副本

- 数据写入
  - 写请求进入主副本节点
    - 分配SN，使用SN创建UpdateRequest
    - 将UpdateRequest插入prepared list
  - 请求从副本节点
    - 主副本节点将UpdateRequest发往从副本节点
    - 从副本节点收到后插入prepared list
    - 从副本节点给主副本节点返回ACK
  - 主副本节点提交
    - 主副本节点收到所有从副本节点响应
    - 将UpdateRequest放入committed list
    - committed list向前移动
  - 完成更新
    - 主副本节点回复客户端更新成功
    - 主副本节点向从副本节点发送commit通知，告知自己的committed point位置
    - 从副本节点收到通知后根据指示移动committed point到相同的位置

- 错误检测——租约(lease)机制
  - 如果主副本节点在一定时间内(lease period)未收到从副本节点的租约回复，则认为从副本节点异常，向配置管理器汇报，将异常从副本移出副本组，同时自己降级，不再作为主副本节点
  - 如果从副本节点在一定时间内(grace period)未收到主副本节点的租约请求，则认为主副本节点异常，向配置管理器汇报，将主副本移出副本组，同时将自己提升为新的主。如果存在多个从，则哪个先执行，就被提升为新的主

### ES数据副本模型

- 数据写入

  - 请求到达协调节点，路由到主分片所在节点
  - 操作在主分片上进行
  - 操作成功后，转发操作到当前in-sync副本组所有副分片
  - 所有副分片成功执行，并回复主分片，主分片返回协调节点，协调节点返回客户端

- 写故障处理

  - 主分片自身错误

    - 发送消息到Master节点
    - 等待(默认最多1min)Master节点提升一个副分片为主分片
    - 操作转发给新主分片

    > Master节点同样会监控节点健康，可能会主动降级主分片

  - 主分片处理成功后，主分片处理副分片潜在发生的错误

    - 发送消息到Master节点，要求把有问题的分片从in-sync replica set中踢出
    - Master确认移除分片
    - 主分片确认这次操作

    > Master也会指导另一个节点建立一个新的副本分片，以便把系统恢复成健康状态

  - 主分片因网络原因被隔离

    > 主分片转发请求到副分片时，会使用副分片来验证它是否仍是一个活跃的主分片

    - 操作被副分片拒绝
    - 访问主节点
    - 得知被替换
    - 将操作转发给新主节点

- 数据查询
  - 请求到达协调节点，把读请求转发到相关分片
  - 从副本组中选择一个活跃副本(默认情况下，ES会简单地循环遍历这些分片)
  - 发送读请求到被选中的副本
  - 合并结果返回客户端(针对通过ID查找的请求，会跳过这个步骤)
- 读故障处理
  
  - 协调节点会从副本组中选择另一个副本，转发请求